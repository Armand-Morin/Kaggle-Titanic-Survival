{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBJECTIVE : Beat the baseline accuracy of ~78.57% (See A_*.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Feature Engineering Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_processed_1.csv', index_col='PassengerId')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test_processed_1.csv', index_col='PassengerId')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Shape :', train.shape)\n",
    "print('Test Shape :', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(data=train, drop_first=True)\n",
    "print('Train Shape :', train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(data=test, drop_first=True)\n",
    "print('Test Shape :', test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 : Split Datasets as x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.pop('Survived')\n",
    "train_x = train\n",
    "print('train_x shape :', train_x.shape)\n",
    "print('train_y shape :', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test # Test-set has no target columns\n",
    "print('test_x shape :', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 : Data Modelling with Logistic Regression Classifier (default params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lrclf = LogisticRegression(random_state=42)\n",
    "lrclf.fit(train_x,train_y)\n",
    "\n",
    "cv_scores = cross_val_score(lrclf, train_x, train_y, cv=3, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores) # [0.79124579 0.8047138  0.79124579]\n",
    "\n",
    "results = lrclf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/predictions/logistic_regression.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 : Data Modelling with SGDClassifier (default params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# By default the param loss='hinge'. When the loss function is 'hinge', it gives linear SVM.\n",
    "# This one below thus gives Linear SVM model\n",
    "sgdclf = SGDClassifier(random_state=42, max_iter=100)\n",
    "sgdclf.fit(train_x,train_y)\n",
    "\n",
    "# Measuring Accuracy with K-fold Cross-Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(sgdclf, train_x, train_y, cv=3, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores) # [0.76767677 0.71043771 0.79124579]\n",
    "\n",
    "sgd_results = sgdclf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : sgd_results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "df.to_csv('data/predictions/sgd.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 : Data Modelling with Logistic Regression Classifier (custom params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "sc = StandardScaler()\n",
    "select_colns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S']\n",
    "sc.fit(train_x[select_colns])\n",
    "\n",
    "train_xx = sc.transform(train_x[select_colns])\n",
    "test_xx = sc.transform(test_x[select_colns])\n",
    "\n",
    "lrclf = LogisticRegression(random_state=42, max_iter=300, C=0.3, solver='sag',n_jobs=3) # C=0.3 maade the real difference here\n",
    "lrclf.fit(train_xx,train_y)\n",
    "\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "cv_scores = cross_val_score(lrclf, train_xx, train_y, cv=cv, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores) \n",
    "# [0.79124579 0.8047138  0.79124579] # Default params and without StandardScaler preprocessing\n",
    "# [0.78787879 0.79124579 0.8047138 ] # With just StandardScaler preprocessing\n",
    "# [0.79124579 0.8047138  0.8013468 ] # With StandardScaler preprocessing and Custom Params\n",
    "# [0.80970149 0.79850746 0.80223881] # With StandardScaler preprocessing, Custom Params and ShuffleSplit cv-strategy\n",
    "results = lrclf.predict(test_xx)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index, # which is 'PassengerId' and its values\n",
    "    'Survived' : results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "# df.head()\n",
    "df.to_csv('data/predictions/logistic_regression_tuned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.Series(data=lrclf.coef_.flatten(),index=select_colns)\n",
    "coeffs\n",
    "# Gosh, Pclass and Sex seem to have got least importance and RoundedFare got highest importance :facepalm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 : Data Modelling with SGDClassifier (custom params) giving Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sc = StandardScaler()\n",
    "select_colns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S'] # Removing 'RoundedFare' yields better accuracy\n",
    "sc.fit(train_x[select_colns])\n",
    "train_xx = sc.transform(train_x[select_colns])\n",
    "test_xx = sc.transform(test_x[select_colns])\n",
    "\n",
    "# By default the param loss='hinge'. When the loss function is 'hinge', it gives linear SVM.\n",
    "sgdclf = SGDClassifier(random_state=42, max_iter=1000, alpha=0.7)\n",
    "sgdclf.fit(train_xx,train_y)\n",
    "\n",
    "# Measuring Accuracy with K-fold Cross-Validation\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "cv_scores = cross_val_score(sgdclf, train_xx, train_y, cv=cv, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores) \n",
    "# [0.76767677 0.71043771 0.79124579] # with default params\n",
    "# [0.79104478 0.79850746 0.82089552] # With SS preprocessing, 1k iterations\n",
    "# [0.82462687 0.82089552 0.79104478] # With SS preprocessing, 1k iterations, alpha=0.7, default loss=hinge\n",
    "sgd_results = sgdclf.predict(test_xx)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : sgd_results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "loss_function_name = sgdclf.loss_function_.__class__.__name__.lower()\n",
    "fname = \"data/predictions/sgd_tuned_with_{0}.csv\".format(loss_function_name)\n",
    "df.to_csv(fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 : Data Modelling with SGDClassifier (custom params) giving Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sc = StandardScaler()\n",
    "select_colns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S'] # Removing 'RoundedFare' yields better accuracy\n",
    "sc.fit(train_x[select_colns])\n",
    "train_xx = sc.transform(train_x[select_colns])\n",
    "test_xx = sc.transform(test_x[select_colns])\n",
    "\n",
    "# By default the param loss='hinge'. When the loss function is 'hinge', it gives linear SVM.\n",
    "# When the loss function is set to 'log', it gives Logistic Regression\n",
    "# For other loss functions see http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# sgdclf = SGDClassifier(random_state=42, max_iter=1000, alpha=0.7)\n",
    "sgdclf = SGDClassifier(random_state=42, max_iter=5000, alpha=0.25, loss='log')\n",
    "sgdclf.fit(train_xx,train_y)\n",
    "\n",
    "# Measuring Accuracy with K-fold Cross-Validation\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "cv_scores = cross_val_score(sgdclf, train_xx, train_y, cv=cv, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores) \n",
    "# [0.76767677 0.71043771 0.79124579] # with default params\n",
    "# [0.79104478 0.79850746 0.82089552] # With SS preprocessing, 1k iterations\n",
    "# [0.82462687 0.82089552 0.79104478] # With SS preprocessing, 1k iterations, alpha=0.7, default loss=hinge\n",
    "# [0.80970149 0.82835821 0.82462687] # With SS preprocessing, 1k iterations, alpha=0.7, loss=log\n",
    "\n",
    "sgd_results = sgdclf.predict(test_xx)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : sgd_results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "loss_function_name = sgdclf.loss_function_.__class__.__name__.lower()\n",
    "fname = \"data/predictions/sgd_tuned_with_{0}.csv\".format(loss_function_name)\n",
    "df.to_csv(fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8 : Data Modelling with SVM Classifier - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sc = StandardScaler()\n",
    "select_colns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S'] # Removing 'RoundedFare' yields better accuracy\n",
    "sc.fit(train_x[select_colns])\n",
    "train_xx = sc.transform(train_x[select_colns])\n",
    "test_xx = sc.transform(test_x[select_colns])\n",
    "\n",
    "C= 1.0 #0.1 \n",
    "svmclf = svm.SVC(kernel='linear', C=C, random_state=42)\n",
    "# svmclf = svm.SVC(kernel='linear', C=C, random_state=42, class_weight={1:2})\n",
    "svmclf.fit(train_xx,train_y)\n",
    "\n",
    "# Measuring Accuracy with K-fold Cross-Validation\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "cv_scores = cross_val_score(svmclf, train_xx, train_y, cv=cv, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores) \n",
    "# [0.79104478 0.79477612 0.79104478]\n",
    "\n",
    "svm_results = svmclf.predict(test_xx)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : svm_results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "\n",
    "kernel_name = svmclf.kernel\n",
    "fname = \"data/predictions/svm_with_{0}_kernel.csv\".format(kernel_name)\n",
    "df.to_csv(fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9 : Data Modelling with SVM Classifier - Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sc = StandardScaler()\n",
    "select_colns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S'] # Removing 'RoundedFare' yields better accuracy\n",
    "sc.fit(train_x[select_colns])\n",
    "train_xx = sc.transform(train_x[select_colns])\n",
    "test_xx = sc.transform(test_x[select_colns])\n",
    "\n",
    "C= 0.75 #1.0\n",
    "svmclf = svm.SVC(kernel='poly', degree=3, C=C, random_state=42)\n",
    "# svmclf = svm.SVC(kernel='poly', degree=3, C=C, random_state=42, class_weight={0:3, 1:5})\n",
    "svmclf.fit(train_xx,train_y)\n",
    "\n",
    "# Measuring Accuracy with K-fold Cross-Validation\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "cv_scores = cross_val_score(svmclf, train_xx, train_y, cv=cv, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores)\n",
    "# [0.81716418 0.82462687 0.81716418] # When degree=2, class_weight is default  and C=0.75 \n",
    "# [0.80223881 0.81343284 0.8358209 ] # When degree=3, class_weight is default  and C=0.75 \n",
    "# [0.80597015 0.80597015 0.80970149] # When degree=3, class_weight={0:3, 1:5} and C=0.75 \n",
    "svm_results = svmclf.predict(test_xx)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : svm_results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "\n",
    "kernel_name = svmclf.kernel\n",
    "fname = \"data/predictions/svm_with_{0}_kernel.csv\".format(kernel_name)\n",
    "df.to_csv(fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10 : Data Modelling with SVM Classifier - Gaussian Radial Basis Function (RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores : [0.81343284 0.8358209  0.82462687]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[525,  24],\n",
       "       [104, 238]], dtype=int64)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sc = StandardScaler()\n",
    "select_colns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S'] # Removing 'RoundedFare' yields better accuracy\n",
    "sc.fit(train_x[select_colns])\n",
    "train_xx = sc.transform(train_x[select_colns])\n",
    "test_xx = sc.transform(test_x[select_colns])\n",
    "\n",
    "C= 0.75\n",
    "svmclf = svm.SVC(kernel='rbf', gamma=0.7, C=C, random_state=42)\n",
    "svmclf.fit(train_xx,train_y)\n",
    "\n",
    "# Measuring Accuracy with K-fold Cross-Validation\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "cv_scores = cross_val_score(svmclf, train_xx, train_y, cv=cv, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores)\n",
    "# [0.81343284 0.8358209  0.82462687] # when C=0.75, kernel='rbf', gamma=0.7\n",
    "\n",
    "svm_results = svmclf.predict(test_xx)\n",
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : svm_results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "\n",
    "kernel_name = svmclf.kernel\n",
    "fname = \"data/predictions/svm_with_{0}_kernel.csv\".format(kernel_name)\n",
    "df.to_csv(fname)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(train_y, svmclf.predict(train_xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores : [0.8358209  0.83955224 0.84701493]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[493,  56],\n",
       "       [ 92, 250]], dtype=int64)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# OBJECTIVE : Tune SVC with GBF Kernel for better results - An attempt.\n",
    "# Notes: \n",
    "# C and Gamma are the parameters for a nonlinear support vector machine (SVM) with a Gaussian radial basis function kernel.\n",
    "# C is the parameter for the soft margin cost function, which controls the influence of each individual support vector; this process involves trading error penalty for stability.\n",
    "# C controls the cost of misclassification on the training data.\n",
    "# Small C makes the cost of misclassificaiton low (\"soft margin\"), thus allowing more of them for the sake of wider \"cushion\".\n",
    "# Large C makes the cost of misclassification high ('hard margin\"), thus forcing the algorithm to explain the input data stricter and potentially overfit.\n",
    "# The goal is to find the balance between \"not too strict\" and \"not too loose\". Cross-validation and resampling, along with grid search, are good ways to finding the best C.\n",
    "# Gamma is the free parameter of the Gaussian radial basis function.\n",
    "# large gamma leads to high bias and low variance models, and vice-versa.\n",
    "# Intuitively, the gamma parameter defines how far the influence of a single training example reaches, \n",
    "# with low values meaning ‘far’ and high values meaning ‘close’. \n",
    "# The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors.\n",
    "#\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sc = StandardScaler()\n",
    "select_colns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S'] # Removing 'RoundedFare' yields better accuracy\n",
    "sc.fit(train_x[select_colns])\n",
    "train_xx = sc.transform(train_x[select_colns])\n",
    "test_xx = sc.transform(test_x[select_colns])\n",
    "\n",
    "C= 2.5 # Cost of mis-classification\n",
    "svmclf = svm.SVC(kernel='rbf', gamma=0.05, C=C, random_state=42, class_weight={1:1.25}) # Gamma is the Bias-factor\n",
    "svmclf.fit(train_xx,train_y)\n",
    "\n",
    "# Measuring Accuracy with K-fold Cross-Validation\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "cv_scores = cross_val_score(svmclf, train_xx, train_y, cv=cv, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores)\n",
    "# [0.81343284 0.8358209  0.82462687] # when C=0.75, kernel='rbf', gamma=0.7\n",
    "# [0.8358209  0.83955224 0.84701493] # when C=2.5, kernel='rbf', gamma=0.05 (improved my ranking in Kaggle by 2722 places)\n",
    "\n",
    "svm_results = svmclf.predict(test_xx)\n",
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : svm_results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "\n",
    "kernel_name = svmclf.kernel\n",
    "fname = \"data/predictions/svm_with_{0}_kernel_tuned.csv\".format(kernel_name)\n",
    "df.to_csv(fname)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(train_y, svmclf.predict(train_xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores : [0.82462687 0.8358209  0.85074627]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[507,  42],\n",
       "       [100, 242]], dtype=int64)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sc = StandardScaler()\n",
    "select_colns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S'] # Removing 'RoundedFare' yields better accuracy\n",
    "sc.fit(train_x[select_colns])\n",
    "train_xx = sc.transform(train_x[select_colns])\n",
    "test_xx = sc.transform(test_x[select_colns])\n",
    "\n",
    "C= 1.0 # Cost of mis-classification\n",
    "svmclf = svm.SVC(kernel='rbf', gamma=0.1, C=C, random_state=42) # Gamma is the Bias-factor\n",
    "svmclf.fit(train_xx,train_y)\n",
    "\n",
    "# Measuring Accuracy with K-fold Cross-Validation\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "cv_scores = cross_val_score(svmclf, train_xx, train_y, cv=cv, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores)\n",
    "# [0.81343284 0.8358209  0.82462687] # when C=0.75, gamma=0.7\n",
    "# [0.8358209  0.83955224 0.84701493] # when C=2.5, gamma=0.05, class_weight={1:1.25} (improved my ranking in Kaggle by 2722 places)\n",
    "# [0.80246914 0.80246914 0.77777778] # when C=100, gamma=0.3 # Scored 0.76076, equivalent to LR in Kaggle. Bad!\n",
    "# [0.82462687 0.8358209  0.85074627] # when C=1.0, gamma=0.1\n",
    "\n",
    "svm_results = svmclf.predict(test_xx)\n",
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : svm_results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "\n",
    "kernel_name = svmclf.kernel\n",
    "fname = \"data/predictions/svm_with_{0}_kernel_tuned2.csv\".format(kernel_name)\n",
    "df.to_csv(fname)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(train_y, svmclf.predict(train_xx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11 : Data Modelling with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def round_single(n):\n",
    "    return np.round(n,decimals=1)\n",
    "\n",
    "def round_double(n):\n",
    "    return np.round(n,decimals=2)\n",
    "\n",
    "def range_simple(start,end,step, decimal=1):\n",
    "    lst = list(np.arange(start,end,step))\n",
    "    mp = map(round_single, lst) if decimal==1 else map(round_double, lst) # Python's Ternary Operator\n",
    "    lst = list(mp)\n",
    "    return lst\n",
    "\n",
    "tpl_c = range_simple(0.1,2.1,0.1) + [3,5]\n",
    "tpl_gamma = tuple(range_simple(0.01,1.01,0.01,decimal=2))\n",
    "len(tpl_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2200 candidates, totalling 6600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 935 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2435 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4535 tasks      | elapsed:  1.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.8361391694725028\n",
      "\tclf__C \t 5.00\n",
      "\tclf__gamma \t 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 6600 out of 6600 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "sc = StandardScaler()\n",
    "select_colns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S'] # Removing 'RoundedFare' yields better accuracy\n",
    "sc.fit(train_x[select_colns])\n",
    "train_xx = sc.transform(train_x[select_colns])\n",
    "test_xx = sc.transform(test_x[select_colns])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf',svm.SVC(kernel='rbf', gamma=0.1, C=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "'''\n",
    "params = {\n",
    "    'clf__C':(0.1,0.5,1,2,3,5,10),\n",
    "    'clf__gamma':(0.01,0.1,0.2,0.3,0.5,0.7,0.9,1.0)\n",
    "}\n",
    "'''\n",
    "\n",
    "params = {\n",
    "    'clf__C':tuple(range_simple(0.1,2.1,0.1) + [3,5]),\n",
    "    'clf__gamma':tuple(range_simple(0.01,1.01,0.01,decimal=2))\n",
    "}\n",
    "\n",
    "grid_svm_rbf = GridSearchCV(pipeline,\n",
    "                           params,\n",
    "                           n_jobs=-1,\n",
    "                           cv=3,\n",
    "                           verbose=1,\n",
    "                           scoring='accuracy')\n",
    "\n",
    "grid_svm_rbf.fit(train_xx, train_y)\n",
    "best_score = grid_svm_rbf.best_score_\n",
    "print('Best Score : ', best_score)\n",
    "\n",
    "best_params = grid_svm_rbf.best_estimator_.get_params()\n",
    "for k in sorted(params.keys()):\n",
    "    print('\\t{0} \\t {1:.2f}'.format(k, best_params[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2200 candidates, totalling 6600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2494 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 6494 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=-1)]: Done 6600 out of 6600 | elapsed:   53.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2200 candidates, totalling 6600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1559 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 4059 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=-1)]: Done 6600 out of 6600 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2200 candidates, totalling 6600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2163 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 5663 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=-1)]: Done 6600 out of 6600 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores : [0.80223881 0.83208955 0.84701493]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[524,  25],\n",
       "       [115, 227]], dtype=int64)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_results = grid_svm_rbf.predict(test_xx)\n",
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : svm_results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "\n",
    "fname = \"data/predictions/svm_with_svm_rbf_optimized_by_grid_search.csv\"\n",
    "df.to_csv(fname)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(train_y, grid_svm_rbf.predict(train_xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
