{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBJECTIVE : Beat the baseline accuracy of ~78.57% (See A_*.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Feature Engineering Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_processed_1.csv', index_col='PassengerId')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test_processed_1.csv', index_col='PassengerId')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Shape :', train.shape)\n",
    "print('Test Shape :', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(data=train, drop_first=True)\n",
    "print('Train Shape :', train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(data=test, drop_first=True)\n",
    "print('Test Shape :', test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 : Split Datasets as x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.pop('Survived')\n",
    "train_x = train\n",
    "print('train_x shape :', train_x.shape)\n",
    "print('train_y shape :', train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test # Test-set has no target columns\n",
    "print('test_x shape :', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 : Data Modelling with Logistic Regression Classifier (default params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lrclf = LogisticRegression(random_state=42)\n",
    "lrclf.fit(train_x,train_y)\n",
    "\n",
    "cv_scores = cross_val_score(lrclf, train_x, train_y, cv=3, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores) # [0.79124579 0.8047138  0.79124579]\n",
    "\n",
    "results = lrclf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/predictions/logistic_regression.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 : Data Modelling with SGDClassifier (default params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# By default the param loss='hinge'. When the loss function is 'hinge', it gives linear SVM.\n",
    "# This one below thus gives Linear SVM model\n",
    "sgdclf = SGDClassifier(random_state=42, max_iter=100)\n",
    "sgdclf.fit(train_x,train_y)\n",
    "\n",
    "# Measuring Accuracy with K-fold Cross-Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(sgdclf, train_x, train_y, cv=3, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores) # [0.76767677 0.71043771 0.79124579]\n",
    "\n",
    "sgd_results = sgdclf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : sgd_results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "df.to_csv('data/predictions/sgd.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 : Data Modelling with Logistic Regression Classifier (custom params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "sc = StandardScaler()\n",
    "select_colns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S']\n",
    "sc.fit(train_x[select_colns])\n",
    "\n",
    "train_xx = sc.transform(train_x[select_colns])\n",
    "test_xx = sc.transform(test_x[select_colns])\n",
    "\n",
    "lrclf = LogisticRegression(random_state=42, max_iter=300, C=0.3, solver='sag',n_jobs=3) # C=0.3 maade the real difference here\n",
    "lrclf.fit(train_xx,train_y)\n",
    "\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "cv_scores = cross_val_score(lrclf, train_xx, train_y, cv=cv, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores) \n",
    "# [0.79124579 0.8047138  0.79124579] # Default params and without StandardScaler preprocessing\n",
    "# [0.78787879 0.79124579 0.8047138 ] # With just StandardScaler preprocessing\n",
    "# [0.79124579 0.8047138  0.8013468 ] # With StandardScaler preprocessing and Custom Params\n",
    "# [0.80970149 0.79850746 0.80223881] # With StandardScaler preprocessing, Custom Params and ShuffleSplit cv-strategy\n",
    "results = lrclf.predict(test_xx)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index, # which is 'PassengerId' and its values\n",
    "    'Survived' : results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "# df.head()\n",
    "df.to_csv('data/predictions/logistic_regression_tuned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.Series(data=lrclf.coef_.flatten(),index=select_colns)\n",
    "coeffs\n",
    "# Gosh, Pclass and Sex seem to have got least importance and RoundedFare got highest importance :facepalm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 : Data Modelling with SGDClassifier (custom params) giving Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sc = StandardScaler()\n",
    "select_colns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S'] # Removing 'RoundedFare' yields better accuracy\n",
    "sc.fit(train_x[select_colns])\n",
    "train_xx = sc.transform(train_x[select_colns])\n",
    "test_xx = sc.transform(test_x[select_colns])\n",
    "\n",
    "# By default the param loss='hinge'. When the loss function is 'hinge', it gives linear SVM.\n",
    "sgdclf = SGDClassifier(random_state=42, max_iter=1000, alpha=0.7)\n",
    "sgdclf.fit(train_xx,train_y)\n",
    "\n",
    "# Measuring Accuracy with K-fold Cross-Validation\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "cv_scores = cross_val_score(sgdclf, train_xx, train_y, cv=cv, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores) \n",
    "# [0.76767677 0.71043771 0.79124579] # with default params\n",
    "# [0.79104478 0.79850746 0.82089552] # With SS preprocessing, 1k iterations\n",
    "# [0.82462687 0.82089552 0.79104478] # With SS preprocessing, 1k iterations, alpha=0.7, default loss=hinge\n",
    "sgd_results = sgdclf.predict(test_xx)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : sgd_results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "loss_function_name = sgdclf.loss_function_.__class__.__name__.lower()\n",
    "fname = \"data/predictions/sgd_tuned_with_{0}.csv\".format(loss_function_name)\n",
    "df.to_csv(fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 : Data Modelling with SGDClassifier (custom params) giving Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "sc = StandardScaler()\n",
    "select_colns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Sex_male', 'Embarked_Q', 'Embarked_S'] # Removing 'RoundedFare' yields better accuracy\n",
    "sc.fit(train_x[select_colns])\n",
    "train_xx = sc.transform(train_x[select_colns])\n",
    "test_xx = sc.transform(test_x[select_colns])\n",
    "\n",
    "# By default the param loss='hinge'. When the loss function is 'hinge', it gives linear SVM.\n",
    "# When the loss function is set to 'log', it gives Logistic Regression\n",
    "# For other loss functions see http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "# sgdclf = SGDClassifier(random_state=42, max_iter=1000, alpha=0.7)\n",
    "sgdclf = SGDClassifier(random_state=42, max_iter=5000, alpha=0.25, loss='log')\n",
    "sgdclf.fit(train_xx,train_y)\n",
    "\n",
    "# Measuring Accuracy with K-fold Cross-Validation\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.3, random_state=42)\n",
    "cv_scores = cross_val_score(sgdclf, train_xx, train_y, cv=cv, scoring='accuracy')\n",
    "print('CV Scores :', cv_scores) \n",
    "# [0.76767677 0.71043771 0.79124579] # with default params\n",
    "# [0.79104478 0.79850746 0.82089552] # With SS preprocessing, 1k iterations\n",
    "# [0.82462687 0.82089552 0.79104478] # With SS preprocessing, 1k iterations, alpha=0.7, default loss=hinge\n",
    "# [0.80970149 0.82835821 0.82462687] # With SS preprocessing, 1k iterations, alpha=0.7, loss=log\n",
    "\n",
    "sgd_results = sgdclf.predict(test_xx)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    test_x.index.name : test_x.index,\n",
    "    'Survived' : sgd_results\n",
    "    })\n",
    "df.set_index(test_x.index.name, inplace=True)\n",
    "loss_function_name = sgdclf.loss_function_.__class__.__name__.lower()\n",
    "fname = \"data/predictions/sgd_tuned_with_{0}.csv\".format(loss_function_name)\n",
    "df.to_csv(fname)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
